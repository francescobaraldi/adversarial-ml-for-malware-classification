import gurobipy as gp
from gurobipy import GRB
import torch
import pandas as pd


def read_bounds(path, hidden_layers):
    '''
    Reads the bounds stored in a csv file for a specific DNN
    
    :param path: (str) path to the csv file
    :hidden_layer: (list) that represtens the hidden layers of the net
    :return: two list of list containing for each neuron of each layer the resp. bound
    '''
    
    num_layers = len(hidden_layers)
    df = pd.read_csv(path)
    x_bounds = []
    s_bounds = []
    for k in range(num_layers):
        x_k = list(df[f"x_{k}"])
        s_k = list(df[f"s_{k}"])
        x_bounds.append(x_k)
        s_bounds.append(s_k)
    
    return x_bounds, s_bounds


def compute_bounds(weights, biases, input, k, j, MAX_ERROR = 20, TIME_LIMIT = 10, LOG = True):
    '''
    Compute the improved bounds for the j-th neuron of the k-th layer using the method presented by Fischetti and Jo
    
    :param weights: (list) containing the weights of the DNN
    :param biases: (list) containing the biases of the DNN
    :param input: (torch.Tensor) input sample
    :param k: (int) layer
    :param j: (int) neuron
    :param MAX_ERROR: (int) max number of features changed between the original input and the adversarial input crafted
    :param TIME_LIMIT: (int) time limit for each run
    :param LOG: (bool) if True print to stdout the info about the run
    :return: improved bounds for x and s variable
    '''
    
    dim_input = input.shape[0]
    num_hidden = k + 1
    
    m = gp.Model('MalwareDetection')
    m.setParam('TimeLimit', TIME_LIMIT)
    
    x_input = m.addVars(dim_input, name='x_input', vtype=GRB.BINARY)
    x_hidden = []
    s_hidden = []
    z_hidden = []
    for i in range(num_hidden):
        if i == k:
            x_vars = m.addVars(1, name="x_hidden_%d" % i, vtype=GRB.CONTINUOUS)
            s_vars = m.addVars(1, name="s_hidden_%d" % i, vtype=GRB.CONTINUOUS)
            z_vars = m.addVars(1, name="z_hidden_%d" % i, vtype=GRB.BINARY)
        else:
            x_vars = m.addVars(weights[i].shape[0], name="x_hidden_%d" % i, vtype=GRB.CONTINUOUS)
            s_vars = m.addVars(weights[i].shape[0], name="s_hidden_%d" % i, vtype=GRB.CONTINUOUS)
            z_vars = m.addVars(weights[i].shape[0], name="z_hidden_%d" % i, vtype=GRB.BINARY)
        x_hidden.append(x_vars)
        s_hidden.append(s_vars)
        z_hidden.append(z_vars)
    
    error = m.addVar(name="error", ub=MAX_ERROR, vtype=GRB.INTEGER)
    
    m.addConstr(gp.quicksum((x_input[i] - input[i])**2 for i in range(dim_input)) <= error)
    
    for n in range(len(x_hidden[0])):
        if k == 0:
            m.addConstr(gp.quicksum(x_input[i] * weights[0][j][i] for i in range(dim_input)) + biases[0][j] == x_hidden[0][n] - s_hidden[0][n])
        else:
            m.addConstr(gp.quicksum(x_input[i] * weights[0][n][i] for i in range(dim_input)) + biases[0][n] == x_hidden[0][n] - s_hidden[0][n])
    for l in range(1, num_hidden):
        for n in range(len(x_hidden[l])):
            if k == l:
                m.addConstr(gp.quicksum(x_hidden[l - 1][i] * weights[l][j][i] for i in range(len(x_hidden[l - 1]))) + biases[l][j] == x_hidden[l][n] - s_hidden[l][n])
            else:
                m.addConstr(gp.quicksum(x_hidden[l - 1][i] * weights[l][n][i] for i in range(len(x_hidden[l - 1]))) + biases[l][n] == x_hidden[l][n] - s_hidden[l][n])
    
    for l in range(num_hidden):
        for n in range(len(x_hidden[l])):
            m.addGenConstrIndicator(z_hidden[l][n], True, x_hidden[l][n] <= 0)
            m.addGenConstrIndicator(z_hidden[l][n], False, s_hidden[l][n] <= 0)
    
    if not LOG:
        m.setParam('LogToConsole', 0)
        m.setParam('OutputFlag', 0)
        
    x = None
    s = None
    
    m.setObjective(x_hidden[k][0], GRB.MAXIMIZE)
    m.optimize()
    if m.status == GRB.Status.INFEASIBLE:
        x = None
    else:
        x = m.ObjVal
        
    m.setObjective(s_hidden[k][0], GRB.MAXIMIZE)
    m.optimize()
    if m.status == GRB.Status.INFEASIBLE:
        s = None
    else:
        s = m.ObjVal
    
    return x, s


def compute_adv_instance(weights, biases, input, bounds = None, MAX_ERROR = 20, TIME_LIMIT = 2 * 60, LOG = True):
    '''
    Craft the adversarial instance starting from the input and using the weights passed as parameters
    
    :param weights: (list) containing the weights of the DNN
    :param biases: (list) containing the biases of the DNN
    :param input: (torch.Tensor) input sample
    :param bounds: (dict) if given contains the optimized bounds for each neuron of each hidden layer
    :param MAX_ERROR: (int) max number of features changed between the original input and the adversarial input crafted
    :param TIME_LIMIT: (int) time limit for each run
    :param LOG: (bool) if True print to stdout the info about the run
    :return: adversarial instance crafted, runtime in seconds, gap between the best bound and the solution found
    '''
    
    dim_input = input.shape[0]
    num_hidden = len(weights) - 1
    
    m = gp.Model('MalwareDetection')
    m.setParam('TimeLimit', TIME_LIMIT)
    
    x_input = m.addVars(dim_input, name='x_input', vtype=GRB.BINARY)
    x_hidden = []
    s_hidden = []
    z_hidden = []
    for i in range(len(weights) - 1):
        x_vars = m.addVars(weights[i].shape[0], name="x_hidden_%d" % i, vtype=GRB.CONTINUOUS)
        s_vars = m.addVars(weights[i].shape[0], name="s_hidden_%d" % i, vtype=GRB.CONTINUOUS)
        z_vars = m.addVars(weights[i].shape[0], name="z_hidden_%d" % i, vtype=GRB.BINARY)
        x_hidden.append(x_vars)
        s_hidden.append(s_vars)
        z_hidden.append(z_vars)
    error = m.addVar(name="error", ub=MAX_ERROR, vtype=GRB.INTEGER)
    output = m.addVar(name="output", lb=0.55)  # Impongo che l'uscita sia maggiore di 0.55, cioÃ¨ che la risposta della rete sia 1

    m.setObjective(error, GRB.MINIMIZE)
    
    m.addConstr(gp.quicksum((x_input[i] - input[i])**2 for i in range(dim_input)) <= error)
    
    if bounds is not None:
        x_bounds = bounds["x_bounds"]
        s_bounds = bounds["s_bounds"]
        for k in range(num_hidden):
            for j in range(weights[k].shape[0]):
                m.addConstr(x_hidden[k][j] <= x_bounds[k][j])
                m.addConstr(s_hidden[k][j] <= s_bounds[k][j])
    
    for n in range(len(x_hidden[0])):
        m.addConstr(gp.quicksum(x_input[i] * weights[0][n][i] for i in range(dim_input)) + biases[0][n] == x_hidden[0][n] - s_hidden[0][n])
    for l in range(1, num_hidden):
        for n in range(len(x_hidden[l])):
            m.addConstr(gp.quicksum(x_hidden[l - 1][i] * weights[l][n][i] for i in range(len(x_hidden[l - 1]))) + biases[l][n] == x_hidden[l][n] - s_hidden[l][n])
    l = num_hidden
    n = 0  # L'output layer ha un solo neurone
    m.addConstr(gp.quicksum(x_hidden[l - 1][i] * weights[l][n][i] for i in range(len(x_hidden[l - 1]))) + biases[l][n] == output)
    
    for l in range(num_hidden):
        for n in range(len(x_hidden[l])):
            m.addGenConstrIndicator(z_hidden[l][n], True, x_hidden[l][n] <= 0)
            m.addGenConstrIndicator(z_hidden[l][n], False, s_hidden[l][n] <= 0)
    
    # m.write("MalwareDetection.lp")
    
    if not LOG:
        m.setParam('LogToConsole', 0)
        m.setParam('OutputFlag', 0)
    
    m.optimize()
    
    if m.status == GRB.Status.INFEASIBLE:
        return None, None, None
    
    adversarial_example = torch.zeros(dim_input)
    for i in range(dim_input):
        adversarial_example[i] = x_input[i].x
    
    return adversarial_example, m.Runtime, m.MIPGap
