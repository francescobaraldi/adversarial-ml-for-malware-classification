{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZUoreevUxHu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from MILP import compute_adv_instance, compute_bounds, read_bounds\n",
        "from nets import Net, eval_acc\n",
        "from dataset import MyDataset\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "SEED = 21\n",
        "torch.manual_seed(SEED)\n",
        "TRAIN_FROM_SCRATCH = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"dataset_malware/drebin-215-dataset-5560malware-9476-benign.csv\")\n",
        "x = df.drop(columns=['class']).to_numpy().astype(np.float32)\n",
        "y = df['class'].to_numpy()\n",
        "# 'B' = bening -> '1'\n",
        "# 'S' = malware -> '0'\n",
        "y = np.where(y == 'B', 1.0, 0.0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZDUGhhd5K72"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED, shuffle=True)\n",
        "train_dataset = MyDataset(x_train, y_train)\n",
        "test_dataset = MyDataset(x_test, y_test)\n",
        "\n",
        "dl_train = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
        "dl_test = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reti da testare\n",
        "#\n",
        "# [8, 8, 8]\n",
        "# [20, 10, 8, 8]\n",
        "# [20, 20, 10, 10, 10]\n",
        "# [50, 50]\n",
        "# [100, 100]\n",
        "#\n",
        "\n",
        "num_epochs = 50\n",
        "dim_input = 215\n",
        "dim_output = 1\n",
        "hidden_layers = [8, 8, 8]\n",
        "learning_rate = 0.01\n",
        "model = Net(dim_input, hidden_layers, dim_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare the DNN (train from scratch or load the weights from file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if TRAIN_FROM_SCRATCH:\n",
        "  loss_fun = nn.BCELoss()\n",
        "  opt = torch.optim.SGD(model.parameters(), learning_rate)\n",
        "  \n",
        "  train_acc = 0\n",
        "  test_acc = 0\n",
        "  for i in range(num_epochs):\n",
        "    train_acc = eval_acc(model, dl_train)\n",
        "    test_acc = eval_acc(model, dl_test)\n",
        "\n",
        "    for x, y in dl_train:\n",
        "      opt.zero_grad()\n",
        "      y = y.unsqueeze(1).to(torch.float32)\n",
        "      y_pred = model(x)\n",
        "      loss = loss_fun(y_pred, y)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "    \n",
        "    print(f\"Epoch {i} train acc.: {train_acc:.3f} - test acc.: {test_acc:.3f}\")\n",
        "  \n",
        "  # Save the weights to file\n",
        "  torch.save(model.state_dict(), ROOT_DIR + f\"/params/net_{hidden_layers}_params.pth\")\n",
        "else:\n",
        "  # Load the weights from file\n",
        "  model.load_state_dict(torch.load(ROOT_DIR + f\"/params/net_{hidden_layers}_params.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare the lists for weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = list(model.children())[0]\n",
        "weights = []\n",
        "biases = []\n",
        "for layer in layers:\n",
        "    if type(layer) == type(nn.Linear(1, 1)):\n",
        "        weights.append(layer.state_dict()['weight'])\n",
        "        biases.append(layer.state_dict()['bias'])\n",
        "# for w in weights:\n",
        "#     print(w.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Collect all the samples in the testset classified as \"malware\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_tests = []  # List that contains all the sample classified as malware\n",
        "for x, y in dl_test:\n",
        "    for i, el in enumerate(y):\n",
        "        if el == 0.0:\n",
        "            x_tests.append(x[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare the optimized bounds (compute them from scratch or load from file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_bounds = []\n",
        "s_bounds = []\n",
        "if TRAIN_FROM_SCRATCH:\n",
        "    # Compute the improved bounds for each neuron of each layer\n",
        "    for k in range(len(weights) - 1):\n",
        "        x_k = []\n",
        "        s_k = []\n",
        "        for j in range(weights[k].shape[0]):\n",
        "            x, s = compute_bounds(weights, biases, x_test, k, j, MAX_ERROR=20, TIME_LIMIT=10, LOG = False)\n",
        "            x_k.append(x)\n",
        "            s_k.append(s)\n",
        "        x_bounds.append(x_k)\n",
        "        s_bounds.append(s_k)\n",
        "    \n",
        "    # Save them to file\n",
        "    bounds_file = open(ROOT_DIR + f\"/bounds/net_{hidden_layers}_bounds.csv\", \"w\")\n",
        "    for k in range(len(weights) - 1):\n",
        "        bounds_file.write(f\"x_{k},s_{k},\")\n",
        "    max_depth = max(hidden_layers)\n",
        "    for j in range(max_depth):\n",
        "        bounds_file.write(\"\\n\")\n",
        "        for k in range(len(weights) - 1):\n",
        "            if hidden_layers[k] <= j:\n",
        "                bounds_file.write(\",,\")\n",
        "            else:\n",
        "                bounds_file.write(f\"{x_bounds[k][j]},{s_bounds[k][j]},\")\n",
        "    bounds_file.close()\n",
        "else:\n",
        "    # Load the improved bounds from file\n",
        "    x_bounds, s_bounds = read_bounds(ROOT_DIR + f\"/bounds/net_{hidden_layers}_bounds.csv\", hidden_layers)\n",
        "\n",
        "bounds = {\n",
        "    \"x_bounds\": x_bounds,\n",
        "    \"s_bounds\": s_bounds\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the MILP approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TIME_LIMIT = 2 * 60\n",
        "filename = f\"/outputs/net_{hidden_layers}.txt\"\n",
        "output_file = open(ROOT_DIR + filename, \"w\")\n",
        "output_file.write(f\"Rete: {hidden_layers}\")\n",
        "num_opt = 0\n",
        "num_solved_timelimit = 0\n",
        "num_unsolved = 0\n",
        "num_test_instances = 50\n",
        "times = []\n",
        "gaps = []\n",
        "for x_test in tqdm(x_tests[:num_test_instances + 1]):\n",
        "    adversarial_example, runtime, gap = compute_adv_instance(weights=weights, biases=biases, input=x_test, MAX_ERROR=20, TIME_LIMIT=TIME_LIMIT, LOG=False)\n",
        "    if adversarial_example is None:\n",
        "        num_unsolved += 1\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "        output_file.write(\"\\nThe model didn't compute any feasible solution.\")\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "    else:\n",
        "        times.append(runtime)\n",
        "        gaps.append(gap)\n",
        "        adversarial_example[[adversarial_example == -0.0]] = 0.0\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "        if gap == 0:\n",
        "            num_opt += 1\n",
        "        else:\n",
        "            num_solved_timelimit += 1\n",
        "        output_file.write(f\"\\nSolution found in {runtime:.3f} s\")\n",
        "        output_file.write(f\"\\nGap: {gap * 100} %\")\n",
        "        output_file.write(f\"\\nNumbers of features changed: {torch.sum(adversarial_example != x_test).item()}\")\n",
        "        output_file.write(f\"\\nThe original classification is {model(torch.unsqueeze(x_test, 0)).item():.3f}\")\n",
        "        output_file.write(f\"\\nThe classification of the adversarial example is {model(torch.unsqueeze(adversarial_example, 0)).item():.3f}\")\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "output_file.write(f\"\\n\\nNumber of instances unsolved: {num_unsolved} ({(num_unsolved / num_test_instances) * 100:.1f} %)\")\n",
        "output_file.write(f\"\\nNumber of instances solved within time limit: {num_opt} ({(num_opt / num_test_instances) * 100:.1f} %)\")\n",
        "output_file.write(f\"\\nNumber of instances solved exceeding the time limit: {num_solved_timelimit} ({(num_solved_timelimit / num_test_instances) * 100:.1f} %)\")\n",
        "if len(times) != 0 and len(gaps) != 0:\n",
        "    avg_time = sum(times) / len(times)\n",
        "    avg_gap = sum(gaps) / len(gaps)\n",
        "    output_file.write(f\"\\nAverage time: {avg_time:.3f} s\")\n",
        "    output_file.write(f\"\\nAverage gap: {avg_gap * 100:.3f} %\")\n",
        "else:\n",
        "    output_file.write(f\"\\nAll instances unsolved.\")\n",
        "output_file.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing the improved MILP approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TIME_LIMIT = 2 * 60\n",
        "filename = f\"/outputs/net_{hidden_layers}_improved.txt\"\n",
        "output_file = open(ROOT_DIR + filename, \"w\")\n",
        "output_file.write(f\"Rete: {hidden_layers}\")\n",
        "num_opt = 0\n",
        "num_solved_timelimit = 0\n",
        "num_unsolved = 0\n",
        "num_test_instances = 50\n",
        "times = []\n",
        "gaps = []\n",
        "for x_test in tqdm(x_tests[:num_test_instances + 1]):\n",
        "    adversarial_example, runtime, gap = compute_adv_instance(weights=weights, biases=biases, input=x_test, bounds=bounds, MAX_ERROR=20, TIME_LIMIT=TIME_LIMIT, LOG=False)\n",
        "    if adversarial_example is None:\n",
        "        num_unsolved += 1\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "        output_file.write(\"\\nThe model didn't compute any feasible solution.\")\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "    else:\n",
        "        times.append(runtime)\n",
        "        gaps.append(gap)\n",
        "        adversarial_example[[adversarial_example == -0.0]] = 0.0\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "        if gap == 0:\n",
        "            num_opt += 1\n",
        "        else:\n",
        "            num_solved_timelimit += 1\n",
        "        output_file.write(f\"\\nSolution found in {runtime:.3f} s\")\n",
        "        output_file.write(f\"\\nGap: {gap * 100} %\")\n",
        "        output_file.write(f\"\\nNumbers of features changed: {torch.sum(adversarial_example != x_test).item()}\")\n",
        "        output_file.write(f\"\\nThe original classification is {model(torch.unsqueeze(x_test, 0)).item():.3f}\")\n",
        "        output_file.write(f\"\\nThe classification of the adversarial example is {model(torch.unsqueeze(adversarial_example, 0)).item():.3f}\")\n",
        "        output_file.write(\"\\n--------------------------------------------------------------------------\")\n",
        "output_file.write(f\"\\n\\nNumber of instances unsolved: {num_unsolved} ({(num_unsolved / num_test_instances) * 100:.1f} %)\")\n",
        "output_file.write(f\"\\nNumber of instances solved within time limit: {num_opt} ({(num_opt / num_test_instances) * 100:.1f} %)\")\n",
        "output_file.write(f\"\\nNumber of instances solved exceeding the time limit: {num_solved_timelimit} ({(num_solved_timelimit / num_test_instances) * 100:.1f} %)\")\n",
        "if len(times) != 0 and len(gaps) != 0:\n",
        "    avg_time = sum(times) / len(times)\n",
        "    avg_gap = sum(gaps) / len(gaps)\n",
        "    output_file.write(f\"\\nAverage time: {avg_time:.3f} s\")\n",
        "    output_file.write(f\"\\nAverage gap: {avg_gap * 100:.3f} %\")\n",
        "else:\n",
        "    output_file.write(f\"\\nAll instances unsolved.\")\n",
        "output_file.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mlp_sol.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('adm')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff5941aed5ba1c55b8d16c183829a57d82de99aaa0e958207e0cc1d6e1f4e27f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
